# 大模型核心理论

## Transformer

### 整体结构

![【NLP】Transformer模型原理详解](https://pic1.zhimg.com/70/v2-f8d834e3e3387b67f81c8c8c20c3c34d_1440w.image?source=172ae18b&biz_tag=Post)

Outputs是之前生成的结果，作为当前回答的上下文。



### Tokenization

把一段文字，变成一组Token，也就是词元化（Tokenization）

子词词元化：

- “subword”可以拆分成“sub” + “word”两个子词
- “encoded”可以拆解为“encod”+“ed”
- “encoding”可以拆解为“encod”+“ing”

OpenAI的官网上，1000 Tokens大概是750个英文单词上下 / 500个汉字上下



### Embedding

Token变成向量，Token和向量之间是一一对应的关系。

**什么是向量?**

1维向量：坐标[3]，一维空间中的一个点

2维向量：坐标[2, 5]，二维空间中的一个点

3维向量：坐标[-1, 4, -2.5]，三维空间中的一个点

…

512维向量：坐标[3, 5, -2, ……]，512维空间中的一个点

**向量有什么用？**



**one-hot编码的一些问题**

- 维度过高，过于稀疏
  - 容纳n个汉字就需要n x n的映射表

- 没有体现出”距离“概念
  - 如果两个字之间的意思相近，那两个对应的向量求”距离“的时候，就应该更相近

- 没有数学或逻辑关系
  - 最好能满足：国王 - 男人 + 女人 = 女王

 

**Embedding是什么？**

专门把Token映射到新的数学空间（可以理解成一个神经网络）

每个Token都能通过Embedding模型，映射到新的数学空间中的一个点（向量）

![image-20250601120930685](https://github.com/user-attachments/assets/0da64cef-d9f5-45bc-a5f9-e6ad50d1adaa)




### Positional Encoding

一句话的语义除了取决于文字外，还受文字位置的影响。

如：

- 狗咬了猫
- 猫咬了狗

两句话的文字完全一样，因为每个字的位置不同，而得到了完全不同的语义。

Transformer的核心机制是自注意力机制，这个机制在处理输入时是并行的，不像RNN那样一个词一个词地处理。

上一步中的650个字转化出来的1300个向量，每个向量都只表示了一个文字，还需要加入位置信息。

![image-20250601123638952](https://github.com/user-attachments/assets/fec0986a-3844-4531-97bd-3257750de260)




### Encoder & Decoder

Encoder的输出是人类看不懂的（向量），一般用来做分析

Decoder的输出是人类看得懂的（文字、图片、视频），一般用来做生成



![image-20250601125555415](https://github.com/user-attachments/assets/11d91f62-942e-4392-9a89-19b84a94be05)


![image-20250601125959702](https://github.com/user-attachments/assets/e39c7d7b-efab-4e2e-8db6-eadc8f27cd08)


![image-20250601125738945](https://github.com/user-attachments/assets/b665e166-fa52-49cb-a91e-2f00e9634820)


![image-20250601130048340](https://github.com/user-attachments/assets/98195510-5d1a-4944-b3da-b811c0db10f6)




Encoder做的计算是一次性的，只需要理解一次；

Decoder不一样，是一个自回归过程，有了n个字就要输出第n + 1个字



**Encoder**

![image-20250601131033527](https://github.com/user-attachments/assets/da999e54-a31b-4e70-81bf-ade0ff2ca9a4)


Encoder不会改变向量的数量和维度

- 经过Encoder之前的的输入：只包含该位置的语义信息 + 位置信息

- Encoder做的是并行计算的信息聚合，每个词以自己为中心将相关的信息聚合过来

- 经过Encoder之后的输出：信息聚合之后的向量，任何一个向量拿出来都可以代表整个段落，只是侧重点不一样。

  



**Decoder**

![image-20250601132215096](https://github.com/user-attachments/assets/025b8afc-5a27-4d29-8101-4f1b42262028)


Decoder其实也不会改变向量的数量和维度

- 每次计算的输入会有Decoder的输出

- Decoder的输出会经过Linear层和Softmax层输出下一个字



只要Decoder输出一个叫作结束符号的Token，说明回答完毕



**Decoder Only**

最新的大语言模型，几乎都采用了Decoder Only的架构

![image-20250601133734909](https://github.com/user-attachments/assets/1b868431-ec0d-433c-8c5e-368666954388)




### Linear

$$
\text{Linear}(x) = Wx + b
$$

使用Embedding字典，找到与上一个字相关度最高的向量，作为当前的输出



### Softmax

$$
\text{Softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}
$$

Softmax把相关度转换成概率。



### 注意力机制

过去以RNN为核心的Encoder-Decoder有以下几个重要的问题：

- 信息丢失
- 无法处理较长句子
- 不能并行计算

 

**注意力**
$$
\text{Attention}(Q, K, V) = \text{softmax}\left( \frac{QK^\top}{\sqrt{d_k}} \right)V
$$

- Q：Query
- K：Key
- V：Value



### 自注意力机制

自注意力机制中，QKV都变成了一个段落自己本身。

![image-20250601161958885](https://github.com/user-attachments/assets/16a442ff-99c1-4a0c-b649-1e9467a03684)


模型处理词“爱”的时候：

1. 它发出 Query（“我要找和我有关的信息”）
2. 它用这个 Q 去和所有词的 Key 做点积，看看“谁跟我更相关？”
3. 对所有词的 V 加权求和（注意力加权），得到“爱”的新表示


$$
Q = XW^Q, \quad K = XW^K, \quad V = XW^V
$$
![image-20250601163109836](https://github.com/user-attachments/assets/f93af268-9a6c-4652-be0d-3bdb1d391dfa)


  

### 多头自注意力机制

引入多组$W^Q, W^K, W^V$，同时进行多组Self Attention的聚合计算，最后再聚合。

![image-20250601165422709](https://github.com/user-attachments/assets/07de69f1-a10d-469f-936a-b67c05c956dd)

$$
\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \dots, \text{head}_h)W^O
$$

$$
\text{where head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
$$

$$
\text{Attention}(Q, K, V) = \text{softmax} \left( \frac{QK^\top}{\sqrt{d_k}} \right) V
$$



### Feed Forward

Feed Forward就是一个神经网络

![image-20250601171335038](https://github.com/user-attachments/assets/07332238-3797-4561-a9c7-4160d48452f9)


![image-20250601171516505](https://github.com/user-attachments/assets/5883634c-5415-497f-a2b5-27a7739b57f6)


低维 => 高维：信息放大（有用的和没用的放大）

高维 => 低维：提取有用的信息



### 可训练参数

GPT 模型的主要参数来源如下：

| 模块                        | 参数组成                                        | 特点                    |
| --------------------------- | ----------------------------------------------- | ----------------------- |
| 词嵌入层（Token Embedding） | 词表大小 × 隐藏维度 $V \times d_{\text{model}}$ | 通常很大（如词表 50k+） |
| 多层 Transformer Block      | 每层都有 Self-Attention + FFN                   | 重复堆叠，多达几十层    |
| Attention 子模块            | 多个 $W^Q, W^K, W^V, W^O$                       | 通常不是最大头          |
| FFN 子模块                  | 两个大的全连接层 $W_1, W_2$                     | **占大多数参数量**      |
| LayerNorm                   | $\gamma, \beta$，少量参数                       | 微不足道（相对于其他）  |
| 输出层（通常权重共享）      | $W_{\text{out}} \approx \text{Token Embedding}$ | 若共享，则不单独计      |

GPT-2 small为例：

| 模块                           | 参数量估算 | 占比 |
| ------------------------------ | ---------- | ---- |
| Token Embedding（50257×768）   | ≈38M       | ~32% |
| FFN × 12层（每层约8M）         | ≈96M       | ~82% |
| Attention × 12层（每层约1.5M） | ≈18M       | ~15% |
| LayerNorm + others             | <1M        | <1%  |



## 预训练、SFT、RLHF



## Bert / GPT



# 开发工具与API调用

## Prompt工程



## 向量数据库



## LangChain / LangChain4j



## SpringAI



# 高级应用开发

## RAG



## Agent



## Function Calling



## MCP



## 模型微调Fine-Tuning



## 参考

Transformer：https://www.bilibili.com/video/BV12bfPY1E1S/?spm_id_from=333.788.videopod.episodes&vd_source=17605fd94e420129c418e108643d1d6c

